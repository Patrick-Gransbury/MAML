{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5.1\n",
    "\n",
    "Here is a confusion matrix for a classifier of joke funniness. \n",
    "\n",
    "<img src=\"./_media/funny.png\" width=\"350\">\n",
    "\n",
    "Considering *funny* to be the positive outcome, calculate the **(a)** recall, **(b)** precision, **(c)** specificity, **(d)** accuracy, and **(e)** $F_1$ score of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5.2\n",
    "\n",
    "Here is a confusion matrix for a classifier of ice cream flavours. \n",
    "\n",
    "<img src=\"./_media/flavors.png\" width=\"500\">\n",
    "\n",
    "\n",
    "**(a)** Calculate the recall rate for *chocolate*.\n",
    "\n",
    "**(b)** Find the precision for *vanilla*. \n",
    "\n",
    "**(c)** Find the accuracy for *strawberry*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5.3\n",
    "\n",
    "Find the Gini impurity of the set\n",
    "\n",
    "$$ S =  \\{ A, B, B, C, C, C \\}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5.4\n",
    "\n",
    "Explain why for the binary case $K=2$, Definition 5.5 implies that $H(S)$ is maximized when the two classes are equally represented in $S$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5.5\n",
    "\n",
    "Given $x_i=i$ for $i=0,\\ldots,5$, with labels\n",
    "$$\n",
    "y_0=y_4=y_5=A, \\quad y_1=y_2=y_3=B,\n",
    "$$\n",
    "write Python code to find an optimal partition threshold using Gini impurity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5.6\n",
    "\n",
    "For the decision tree drawn in Example 5.10, make predictions for each of the following queries, showing the path taken through the tree for each case:\n",
    "\n",
    "**(a)** $(x_1, x_2) = (4, 5),\\quad$  **(b)** $(x_1, x_2) = (-3, 1),\\quad$  **(c)** $(x_1, x_2) = (10, -1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5.7\n",
    "\n",
    "Using 1-norm, 2-norm, and $\\infty$-norm, find the distance between the given vectors:\n",
    "\n",
    "**(a)** $\\mathbf u=[2,3,0], \\  \\mathbf v=[-2,2,1]$\n",
    "\n",
    "**(b)** $\\mathbf u=[0,1,0,1,0], \\  \\mathbf v=[1,1,1,1,1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5.8\n",
    "\n",
    "**(a)** Prove that for any $\\mathbf u \\in \\mathbb{R}^d$, $\\|\\mathbf u\\|_\\infty \\le \\| \\mathbf u\\|_2$. \n",
    "\n",
    "**(b)** Prove that for any $\\mathbf u \\in \\mathbb{R}^d$, $\\|\\mathbf u\\|_2 \\le \\sqrt{d}\\, \\|\\mathbf u\\|_\\infty$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5.9\n",
    "\n",
    "Carefully sketch the set of all points in $\\mathbb{R}^2$ whose 1-norm distance from the origin equals 1. This is a *Manhattan unit circle*. (Hint: You can consider each quadrant of the plane separately.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5.10\n",
    "\n",
    "Suppose you are training to fit the ground-truth one-dimensional classifier\n",
    "\n",
    "$$\n",
    "y = f(x) =\n",
    "\\begin{cases}\n",
    "+1, & \\text{if } |x| \\leq 2, \\\\\n",
    "-1, & \\text{otherwise}.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Here is a table of training data:\n",
    "\n",
    "| $x_i$ | $-5$ | $-4$ | $-3$ | $-2$ | $-1$ | $0$  | $1$  | $2$  | $3$  | $4$  | $5$  |\n",
    "| ----- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |\n",
    "| $y_i$ | $-1$ | $-1$ | $+1$ | $-1$ | $+1$ | $+1$ | $-1$ | $+1$ | $-1$ | $-1$ | $-1$ |\n",
    "\n",
    "**(a)** Here is a table of testing data:\n",
    "\n",
    "| $t_i$    | $-4.75$ | $-3.75$ | $-2.75$ | $-1.75$ | $-0.75$ | $0.25$ | $1.25$ | $2.25$ | $3.25$ | $4.25$ |\n",
    "| -------- | ------- | ------- | ------- | ------- | ------- | ------ | ------ | ------ | ------ | ------ |\n",
    "| $f(t_i)$ |  $\\,$   | $\\,$    | $\\,$    | $\\,$    | $\\,$    | $\\,$   | $\\,$   | $\\,$   | $\\,$   | $\\,$   |\n",
    "\n",
    "Fill in the second row. \n",
    "\n",
    "**(b)** Add a row to your table from part (a) showing the predictions of a kNN classifier with $k=1$ trained on the given training data.\n",
    "\n",
    "**(c)** Add another row for a kNN classifier with $k=3$. Then add another row for $k=9$.\n",
    "\n",
    "**(d)** Find the testing precision and recall for the rows with $k=1,3,9$, considering $+1$ to be the positive outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5.11\n",
    "\n",
    "Here are blue/orange labels on an integer lattice.\n",
    "\n",
    "<img src=\"_media/gridlabels.png\" width=\"400\">\n",
    "\n",
    "\n",
    "Let $\\hat{f}(x_1,x_2)$ be the kNN probabilistic classifier with $k=4$, Euclidean metric, and mean averaging that returns the probability of a blue label. In each case below, a function $g(t)$ is defined from values of $\\hat{f}$ along a vertical or horizontal line. Carefully sketch a plot of $g(t)$ for $2\\le t \\le 2$. \n",
    "\n",
    "**(a)** $g(t) = \\hat{f}(1.2,t)$ \n",
    "\n",
    "**(b)** $g(t) = \\hat{f}(t,-0.75)$ \n",
    "\n",
    "**(c)** $g(t) = \\hat{f}(t,1.6)$ \n",
    "\n",
    "**(d)** $g(t) = \\hat{f}(-0.25,t)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5.12\n",
    "\n",
    "Suppose you have written a kNN classifier with $k=5$ to predict whether dad jokes are funny. Here are the votes for 6 test jokes:\n",
    "\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-0lax{text-align:left;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\" style=\"undefined;table-layout: fixed; width: 604px\"><colgroup>\n",
    "<col style=\"width: 55%\">\n",
    "<col style=\"width: 14%\">\n",
    "<col style=\"width: 14%\">\n",
    "<col style=\"width: 20%\">\n",
    "</colgroup>\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\">Joke</th>\n",
    "    <th class=\"tg-1wig\">Funny</th>\n",
    "    <th class=\"tg-1wig\">Not funny</th>\n",
    "    <th class=\"tg-1wig\">Actual</th>\n",
    "  </tr></thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">Is the refrigerator running? Better go catch it!</td>\n",
    "    <td class=\"tg-0lax\">3</td>\n",
    "    <td class=\"tg-0lax\">2</td>\n",
    "    <td class=\"tg-0lax\">not funny</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">Why did the scarecrow win an award? Because he was outstanding in his field!</td>\n",
    "    <td class=\"tg-0lax\">1</td>\n",
    "    <td class=\"tg-0lax\">4</td>\n",
    "    <td class=\"tg-0lax\">funny</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">What do you call a fake noodle? An impasta!</td>\n",
    "    <td class=\"tg-0lax\">5</td>\n",
    "    <td class=\"tg-0lax\">0</td>\n",
    "    <td class=\"tg-0lax\">funny</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">Why couldn’t the bicycle stand up by itself? It was two-tired!</td>\n",
    "    <td class=\"tg-0lax\">4</td>\n",
    "    <td class=\"tg-0lax\">1</td>\n",
    "    <td class=\"tg-0lax\">funny</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">What’s blue and not heavy? Light blue.</td>\n",
    "    <td class=\"tg-0lax\">2</td>\n",
    "    <td class=\"tg-0lax\">3</td>\n",
    "    <td class=\"tg-0lax\">not funny</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">What do you call a pile of cats? A meowtain!</td>\n",
    "    <td class=\"tg-0lax\">0</td>\n",
    "    <td class=\"tg-0lax\">5</td>\n",
    "    <td class=\"tg-0lax\">not funny</td>\n",
    "  </tr>\n",
    "</tbody></table>\n",
    "\n",
    "\n",
    "Carefully sketch the ROC curve for this classifier, considering the positive outcome to be \"funny.\"\n",
    "\n",
    "(This exercise is for illustration only. In reality, all the jokes are funny.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5.13\n",
    "\n",
    "Pulsars are detected by scanning for radio frequencies from deep space. However, the vast majority of collected signals are actually terrestrial noise. The following dataset collects 8 statistical features from radio signals and their classifications as noise (class 0) or pulsar (class 1).\n",
    "\n",
    "1. Load  the dataset `pulsars.csv`. Let `y` be the `class` column of the dataset and let `X` be all the remaining columns. Find the proportion of the samples that are actually pulsars.\n",
    "\n",
    "2. Using a random state `19716`, split the data 80% / 20% into testing and training sets.\n",
    "\n",
    "3. Fit a pipeline with standardization scaling and a kNN classifier with $k=8$ to the training data. Since we want to minimize false positives, find its precision score on the test set.\n",
    "\n",
    "4. Perform a grid search on the pipeline defined in step 3, including a search over $k$ from 3 through 20 and over `'uniform'` and `'distance'` for `weights`, using 6 folds in cross-validation and precision as the scoring. Find the best parameters and find the precision score on the test set.\n",
    "\n",
    "5. Using the best model from step 4, make a bagging classifier using 200 estimators, 50% max features and max samples, and random state `302`. Find its precision score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "signals = pd.read_csv(\"_datasets/pulsars.csv\")\n",
    "\n",
    "# TODO: Provide your solution code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "assert X.shape == (17898, 8)\n",
    "assert y.shape == (17898,)\n",
    "assert np.isclose(pulsar_fraction, 0.091574478)\n",
    "\n",
    "assert X_train.shape == (14318, 8)\n",
    "assert y_test.sum() == 326\n",
    "\n",
    "assert np.isclose(knn_score, 0.92982, rtol=1e-5)\n",
    "\n",
    "assert type(best_params) == dict, \"Get the best parameters from the fitted model\"\n",
    "assert grid_score > knn_score, \"Score should have improved\"\n",
    "assert np.isclose(grid_score, 0.93684, rtol=1e-5)\n",
    "\n",
    "assert ensemble_score > grid_score, \"Score should have improved\"\n",
    "assert np.isclose(ensemble_score, 0.952206, rtol=1e-5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
